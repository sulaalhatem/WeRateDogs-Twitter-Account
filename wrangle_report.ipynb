{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>>WeRateDogs - Data Wrangling Report\n",
    "=======\n",
    ">>>>### _Sula Al Hatem_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering The Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were three pieces of data that i needed to collect in three different ways:\n",
    "\n",
    "Getting data from an existing file (twitter-archive-enhanced.csv) Reading from csv file using pandas\n",
    "Downloading a file from the internet (image-predictions.tsv) Downloading file using requests\n",
    "Querying an API (tweet_json.txt) Get JSON object of all the tweet_ids using Tweepy\n",
    "\n",
    "**- Manually downloading an existing file:**\n",
    "* The WeRateDogs Twitter archive. I manually downloaded the file **twitter_archive_enhanced.csv** by clicking the following link: [twitter_archive_enhanced.csv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv)\n",
    "\n",
    "**- Programmatically downloading a file fromthe internet:**\n",
    "* The tweet image predictions, which include data like: what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network. The file **image_predictions.tsv** is hosted on Udacity's servers, i downloaded it programmatically using the Requests library and the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "\n",
    "**- Using API to gather and download data:**\n",
    "* Using the tweet IDs in the WeRateDogs Twitter archive, to get more details, I queried the Twitter API for each tweet's JSON data using Python's Tweepy library and stored each tweet's entire set of JSON data in a file called **tweet_json.txt** file. Each tweet's JSON data should be written to its own line. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assesing The Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intensive visual and programatic assesment was applied on the 3 tables, here are my findings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The WeRateDogs Twitter archive:\n",
    "\n",
    "- tweet_id, in_reply_to_status_id, in_reply_to_user_id are int not string\n",
    "- retweeted_status_id, retweeted_status_user_id are int not string\n",
    "- timestamp and retweeted_status_timestamp are object not datetime\n",
    "- rating_numerator, rating_denominator are int not float so rates like 9.5/10 are captured as 5/10\n",
    "- timestamp and retweeted_status_timestamp has both date and time and a trailing +0000\n",
    "- doggo, floofer, pupper, puppo has missing values\n",
    "- Wrong or missing dogs names and some are in lowercases (but i will not be cleaning since i don't intend to use in my analysis)\n",
    "- Dog ratings have wrong values and some tweets are rating more than one dog \n",
    "- source have 4 unique values and is a string instead of categorical variable\n",
    "- There are 181 retweet entries that we don't need, they are values of retweeted_status_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Tweet Image Predictions\n",
    "\n",
    "- tweet_id is int not string\n",
    "- img_num is float not int\n",
    "- All prediction images in p1, p2 and p3 have inconsistent format (example: redbone and Rottweiler)\n",
    "- All prediction images in p1, p2 and p3 have (_) instead of space \n",
    "- There are 2075 entry only, 281 less than the twitter archive, mostly due to retweet, or lack of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Tweets JSON Data\n",
    "- tweet_id is int not string\n",
    "- favorite_count and retweet_count are floats not int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All 3 tables can be merged  \n",
    "- In **_Tweet Archive_** table, the four columns doggo, floofer, pupper and puppo can be combined in only one column\n",
    "- There are extra columns that are not needed for this analysis in the **_Tweet Archive_** table: retweeted_status_id\tretweeted_status_user_id\tretweeted_status_timestamp in_reply_to_status_id\tin_reply_to_user_id\n",
    "- In **_Tweet Archive_** rating columns don't help much, it would be better to combined them in an percenatge rate column\n",
    "- timestamp_x has both date and time\n",
    "- Breed prediction and confidence prediction are spread on three columns for each prediction\n",
    "- The four columns doggo, floofer, pupper and puppo can be combined in only one\n",
    "- rating_numerator, rating_denominator are in two columns and the unique rating system while shows he enthusiasm about the dog, it might not be a correct comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning The Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First i made sure of making copies of my 3 datasets, so i can keep the original tables intact.\n",
    "For the sake of this analysis, i will not clean all the point mentioned in the assesment part\n",
    "\n",
    "- I decidede to start cleaning some of the messiness in the data first before moving to the quality part. My reason is that i bleive that joining the 3 datasets and removing the unwanted columns and rows, will affect the completence of the data, so i don't need to start working on filling out missing information or correcting wrong ones if they will be eventually removed\n",
    "\n",
    "- While cleaning, new cleaning points came up, i had to go back and for many times to asses the data and update my findings\n",
    "\n",
    "- I decided to ignore the name column, since i didn't inted to use it in my analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
